{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd24bb9c",
   "metadata": {},
   "source": [
    "This Notebook investigates the post-processed data (from the 'dataset_moyennes_matchs.csv' file) by applying various classification models:\n",
    "\n",
    "1- Selection of the most important features and model reduction\n",
    "\n",
    "2- Meta-parameters selection and use of comon classification models\n",
    "\n",
    "3- Comparison of model results applied on a dataset:\n",
    "        - without any modification\n",
    "        - with a feature selection \n",
    "        - applying a dimension reduction\n",
    "   The best model is then compared with the best bookmaker predictions\n",
    "        \n",
    "4- A betting strategy is then proposed and its gain curve is plotted in order to quantify the benefits of using machine learning model for sport bets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Upload\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.getcwd() \n",
    "\n",
    "df = pd.read_csv('dataset_moyennes_matchs.csv', index_col = 0)\n",
    "df = df.reset_index(drop=True).set_index('match_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470ad2e",
   "metadata": {},
   "source": [
    "The dataset is splited (training and test samples): X_train, X_test, y_train, y_test \n",
    "We train the different models from the 2014-2015 season up to the 2016-2017 season, model evaluation is made on the \n",
    "last season, that is the 2017-2018 season. \n",
    "The idea is to consider that after having trained our model we are at the beginning of season 2017 and start applying our models and beting strategy putting ourselve in real conditions. This gives reasonnable proportions: 75% of the dataset for the trainings and 25% for the tests. A classic random spliting can also be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1965a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "feats_list = [ # Features for the 'home' team\n",
    "       'home_team_rating', 'home_won_contest', 'home_possession_percentage', 'home_total_throws', 'home_blocked_scoring_att', \n",
    "       'home_total_scoring_att', 'home_total_tackle', 'home_aerial_won', 'home_aerial_lost', 'home_accurate_pass', \n",
    "       'home_total_pass', 'home_won_corners', 'home_shot_off_target', 'home_ontarget_scoring_att','home_total_offside', \n",
    "       'home_post_scoring_att', 'home_att_pen_goal', 'home_penalty_save', 'HF', 'HY', 'HR', 'home_pass', \n",
    "       'goalkeeper_home_player_rating', 'defender_home_player_rating', 'midfielder_home_player_rating', 'forward_home_player_rating', 'FTHG',       \n",
    "               # Features for the 'away' team\n",
    "       'away_team_rating', 'away_won_contest', 'away_possession_percentage', 'away_total_throws', 'away_blocked_scoring_att',\n",
    "       'away_total_scoring_att', 'away_total_tackle', 'away_aerial_won', 'away_aerial_lost', 'away_accurate_pass', \n",
    "       'away_total_pass', 'away_won_corners', 'away_shot_off_target', 'away_ontarget_scoring_att', 'away_total_offside', \n",
    "       'away_post_scoring_att', 'away_att_pen_goal', 'away_penalty_save', 'AF', 'AY', 'AR', 'away_pass',\n",
    "       'goalkeeper_away_player_rating', 'defender_away_player_rating', 'midfielder_away_player_rating', 'forward_away_player_rating', 'FTAG',\n",
    "        # Team Comparison\n",
    "       'Diff_def_home_fwd_away', 'Diff_def_home_mid_away', 'Diff_mil_home_att_away', 'Diff_mil_home_mid_away',\n",
    "       'Diff_mil_home_def_away', 'Diff_fwd_home_mid_away', 'Diff_fwd_home_def_away', 'Diff_Goal']\n",
    "       \n",
    "# Target\n",
    "target_list = 'FTR'\n",
    "Train = df[df['season']!='2017_2018']\n",
    "Test  = df[df['season']=='2017_2018']\n",
    "\n",
    "\n",
    "X_train = Train[feats_list]\n",
    "X_test  = Test[feats_list]\n",
    "y_train = Train[target_list].reset_index(drop=True)\n",
    "y_test  = Test[target_list].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe display\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardisation\n",
    "from sklearn.preprocessing import StandardScaler     \n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), index = X_train.index, columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), index = X_test.index, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca10bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of features :', len(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1ffc1b",
   "metadata": {},
   "source": [
    "# 1 Dimension reduction of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a69b585",
   "metadata": {},
   "source": [
    "## 1.1 Wrapper RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd8149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function RFECV is considered as it allows the used of various folds. We ahave a classification problem\n",
    "# and a tree classifier is used with the RFECV.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "crossval = KFold(n_splits = 6, random_state = 2, shuffle = True)\n",
    "rfecv = RFECV(estimator=dt, cv = crossval, step=1)\n",
    "rfecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4449649",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal number of features :', rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f36f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Deleted features :', X_train.columns[~rfecv.support_])\n",
    "list_rfecv = X_train.columns[~rfecv.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0bf9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"RFECV Score\")\n",
    "plt.plot(rfecv.grid_scores_);\n",
    "plt.show()\n",
    "# The integer n_features represents the number of features selected by the algorithm.\n",
    "\n",
    "# grid_scores_ gives the mean score by cross-validation for the various iterations. It allows to plot the RFECV score as a \n",
    "# fucntion of the feature number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69e0f3",
   "metadata": {},
   "source": [
    "## 1.2 Logistic Regression with Elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed4855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Logistic regression via easticnet for the feature selection\n",
    "parametres = {'C':[0.1,1,3],'l1_ratio': [0.1, 0.25, 0.8, 0.99]}\n",
    "clf = linear_model.LogisticRegression(penalty = 'elasticnet', solver = 'saga', max_iter = 2000)\n",
    "# High value of max_iter is necessary to ensure convergence\n",
    "grid_clf = GridSearchCV(estimator=clf, param_grid=parametres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grille = grid_clf.fit(X_train,y_train)\n",
    "print('Best parameters:',grid_clf.best_params_) \n",
    "# Remark: Minimum value for C and maximum for l1_ratio are selected. No out of bounds values could be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The feature importance is plotted for the 3 regressions performed (for the 3 possible classes of the target)\n",
    "# Features to be deleted have a zero coefficient\n",
    "optimal_clf = grid_clf.best_estimator_\n",
    "elast_coef = optimal_clf.coef_\n",
    "\n",
    "ticks = np.arange(0, len(elast_coef[0,:]))\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(3,1,figsize=(15,15), sharex = False, sharey = True)\n",
    "ax1.bar(ticks, np.abs(elast_coef[0,elast_coef[0,:].argsort()]))\n",
    "ax1.set_xticks(ticks)\n",
    "ax1.set_xticklabels(X_train.columns.values[elast_coef[0,:].argsort()], rotation='vertical')\n",
    "\n",
    "ax2.bar(ticks, np.abs(elast_coef[1,elast_coef[1,:].argsort()]))\n",
    "ax2.set_xticks(ticks)\n",
    "ax2.set_xticklabels(X_train.columns.values[elast_coef[1,:].argsort()], rotation='vertical')\n",
    "\n",
    "ax3.bar(ticks, np.abs(elast_coef[2,elast_coef[2,:].argsort()]))\n",
    "ax3.set_xticks(ticks)\n",
    "ax3.set_xticklabels(X_train.columns.values[elast_coef[2,:].argsort()], rotation='vertical')\n",
    "ax1.set_title(\"Feature importance: Logistic Regression Coefficients (absolute values)\")\n",
    "plt.subplots_adjust(hspace= 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d5aa6",
   "metadata": {},
   "source": [
    "## 1.3 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# First, the optimal number of vectors to represent the dataset is searched\n",
    "data = df[feats_list]\n",
    "pca = PCA(n_components = 6)\n",
    "pca.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e333c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlim(1,6)\n",
    "plt.plot(np.array(range(1,7)),pca.explained_variance_ratio_);\n",
    "plt.axhline(y = 0.9, color ='r', linestyle = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53928887",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.9)\n",
    "pca.fit(data)\n",
    "print(\"Number of components:\", pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8fa7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As only 2 components are enough, a 2D vizualisation of the data in the reduced space is possible. \n",
    "\n",
    "# PCA 2D plot colored by labels:\n",
    "pca_2D = PCA(n_components = 2)\n",
    "data_2D_pca = pca_2D.fit_transform(data)\n",
    "target = df[target_list].values\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "colors = {'A':'red', 'D':'gray', 'H':'green'}\n",
    "ax.scatter(data_2D_pca[:, 0], data_2D_pca[:, 1], c = df[target_list].map(colors))\n",
    "\n",
    "ax.set_xlabel('PCA 1')\n",
    "ax.set_ylabel('PCA 2')\n",
    "ax.set_title(\"Projected data on PCA Axis\")\n",
    "\n",
    "plt.show();\n",
    "print(\"Explained standard deviation\", round(pca.explained_variance_ratio_.sum(),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70777e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is difficult to separate the different labels in distinct zones using a PCA reduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6744b69",
   "metadata": {},
   "source": [
    "## 1.4 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c834664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA()\n",
    "target = df[target_list].values\n",
    "data_2D_lda = lda.fit_transform(data, target)\n",
    "\n",
    "plt.show()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "colors = {'A':'red', 'D':'gray', 'H':'green'}\n",
    "ax.scatter(data_2D_lda[:, 0], data_2D_lda[:, 1], c = df[target_list].map(colors))\n",
    "ax.set_xlabel('LD 1')\n",
    "ax.set_ylabel('LD 2')\n",
    " \n",
    "ax.set_title(\"Projected data on LDA Axis\")\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is difficult to separate the different labels in distinct zones using a LDA reduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f543dc",
   "metadata": {},
   "source": [
    "## 1.5 Manifold - tNSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582b536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap, TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, method = 'barnes_hut')\n",
    "dataTSNE = tsne.fit_transform(data)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(dataTSNE[:, 0], dataTSNE[:, 1],  c = df[target_list].map(colors))\n",
    "ax.set_title(\"Projected data on 2 TNSE Components\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b0ec2e",
   "metadata": {},
   "source": [
    "## 1.6 Manifold - IsoMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55070f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "isomap = Isomap(n_neighbors=50, n_components=2)\n",
    "dataISO = isomap.fit_transform(data)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(dataISO[:, 0], dataISO[:, 1],  c =df[target_list].map(colors))\n",
    "ax.set_title(\"Projected data on 2 Isomap Components\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no particular method that seems to separate the labels (this does not mean that there are not efficients)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d6e8f",
   "metadata": {},
   "source": [
    "In the rest, 3 different datasets are considered:\n",
    "- A non reduced dataset: the suffix \"_NR\" will be used to specify variables associated with this dataset.\n",
    "\n",
    "- A dataset with selected features via the logistic regression deleting features with zero coefficient of importance. A suffix \"_FS\" will be used to specify variables associated with this dataset.\n",
    "\n",
    "- A reduced dimension dataset: the suffix \"_R\" will be used to specify variables associated with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17572d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset _NR\n",
    "X_train_NR = X_train\n",
    "X_test_NR = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ebbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset _FS\n",
    "\n",
    "# Number of columns having a zero coefficient of importance (for each regression) \n",
    "print(np.size(np.where(optimal_clf.coef_[0,:]==0)))\n",
    "print(np.size(np.where(optimal_clf.coef_[1,:]==0)))\n",
    "print(np.size(np.where(optimal_clf.coef_[2,:]==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af67e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in common:\n",
    "del_col_0 = set(X_train.columns.values[np.where(optimal_clf.coef_[0,:]==0)])\n",
    "del_col_1 = set(X_train.columns.values[np.where(optimal_clf.coef_[1,:]==0)])\n",
    "del_col_2 = set(X_train.columns.values[np.where(optimal_clf.coef_[2,:]==0)])\n",
    "\n",
    "print('Number of columns to be deleted:',len(del_col_0.intersection(del_col_1, del_col_2)),'\\n')\n",
    "print('Variables to be deleted:')\n",
    "print(del_col_0.intersection(del_col_1, del_col_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = list(del_col_0.intersection(del_col_1, del_col_2))\n",
    "X_train_FS = X_train.drop(to_drop, axis=1)\n",
    "X_test_FS  = X_test.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a144a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset _R\n",
    "#X_train_R = pca.fit_transform(X_train)\n",
    "#X_test_R = pca.transform(X_test)\n",
    "\n",
    "X_train_R = tsne.fit_transform(X_train)\n",
    "X_test_R  = tsne.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb54f5",
   "metadata": {},
   "source": [
    "# 2 - Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe3cce",
   "metadata": {},
   "source": [
    "In this section the most comon algorithm are tested for each dataset previously created.\n",
    "For each case, a confusion matrix and a classification report is produced in order to compare the models and measure the benefits of using a reduced dataset or a dataset with selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766df8d9",
   "metadata": {},
   "source": [
    "## 2.1 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "parametres = {'C':[0.05,0.1,1,3],'l1_ratio': [0.01, 0.1, 0.2, 0.5, 0.99]}\n",
    "\n",
    "clf_NR = linear_model.LogisticRegression(penalty = 'elasticnet', solver = 'saga',max_iter = 2000)\n",
    "clf_FS = linear_model.LogisticRegression(penalty = 'elasticnet', solver = 'saga',max_iter = 2000)\n",
    "clf_R  = linear_model.LogisticRegression(penalty = 'elasticnet', solver = 'saga',max_iter = 2000)\n",
    "\n",
    "grid_clf_NR = GridSearchCV(estimator=clf_NR, param_grid=parametres)\n",
    "grid_clf_FS = GridSearchCV(estimator=clf_FS, param_grid=parametres)\n",
    "grid_clf_R = GridSearchCV(estimator=clf_R, param_grid=parametres)\n",
    "\n",
    "grid_clf_NR.fit(X_train_NR,y_train)\n",
    "grid_clf_FS.fit(X_train_FS,y_train)\n",
    "grid_clf_R.fit(X_train_R,y_train)\n",
    "\n",
    "print('Best parameters, non reduced dataset:',grid_clf_NR.best_params_) \n",
    "print('Best parameters, dataset with feature reduction:',grid_clf_FS.best_params_) \n",
    "print('Best parameters, reduced dataset:',grid_clf_R.best_params_) \n",
    "# Remark: Minimum value for C and maximum for l1_ratio are selected. No out of bounds values could be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cfl_NR = grid_clf_NR.predict(X_test_NR)\n",
    "y_pred_cfl_FS = grid_clf_FS.predict(X_test_FS)\n",
    "y_pred_cfl_R  = grid_clf_R.predict(X_test_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report / Results for the reduced dataset are better / Draws are not predicted\n",
    "print('Non reduced Dataset (NR):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_cfl_NR)))\n",
    "print('Dataset with selected features (FS):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_cfl_FS)))\n",
    "print('Reduced Dataset (R):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_cfl_R)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e46588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print('Non reduced Dataset (NR):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_cfl_NR), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6cf091",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset with selected features (FS):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_cfl_FS), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bda4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reduced Dataset (R):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_cfl_R), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d9c8c",
   "metadata": {},
   "source": [
    "## 2.2 K plus proches Voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "# Best parameters selection\n",
    "parametres = {'n_neighbors': [10, 20, 30, 40, 50], 'metric': ['manhattan', 'chebyshev', 'minkowski', 'l1' , 'l2'] }\n",
    "\n",
    "knn_NR = neighbors.KNeighborsClassifier()\n",
    "knn_FS = neighbors.KNeighborsClassifier()\n",
    "knn_R  = neighbors.KNeighborsClassifier()\n",
    "\n",
    "grid_knn_NR = GridSearchCV(estimator=knn_NR, param_grid=parametres)\n",
    "grid_knn_FS = GridSearchCV(estimator=knn_FS, param_grid=parametres)\n",
    "grid_knn_R = GridSearchCV(estimator=knn_R, param_grid=parametres)\n",
    "\n",
    "grid_knn_NR.fit(X_train_NR,y_train)\n",
    "grid_knn_FS.fit(X_train_FS,y_train)\n",
    "grid_knn_R.fit(X_train_R,y_train)\n",
    "\n",
    "print('Best parameters, non reduced dataset:',grid_knn_NR.best_params_) \n",
    "print('Best parameters, dataset with feature reduction:',grid_knn_FS.best_params_) \n",
    "print('Best parameters, reduced dataset:',grid_knn_R.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8cb3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn_NR = grid_knn_NR.predict(X_test_NR)\n",
    "y_pred_knn_FS = grid_knn_FS.predict(X_test_FS)\n",
    "y_pred_knn_R  = grid_knn_R.predict(X_test_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5037c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports / Results for the 3 datasets are similars (the best being obtained for the non reduced dataset) / Few draws are preducted but with a low recall score\n",
    "print('Non reduced Dataset (NR):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_knn_NR)))\n",
    "print('Dataset with Selected Features (FS):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_knn_FS)))\n",
    "print('Reduced Dataset (R):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_knn_R)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa320ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print('Non reduced Dataset (NR):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_knn_NR), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset with selected features (FS):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_knn_FS), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reduced Dataset (R):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_knn_R), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe93d385",
   "metadata": {},
   "source": [
    "## 2.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "\n",
    "parametres = {'C':[0.1,1,3,5], 'kernel':['rbf','linear'], 'gamma':[0.001, 0.005, 0.01, 0.1]}# Cross validation\n",
    "\n",
    "clf_svm_NR = svm.SVC(probability=True)\n",
    "clf_svm_FS = svm.SVC(probability=True)\n",
    "clf_svm_R = svm.SVC(probability=True)\n",
    "\n",
    "grid_clf_svm_NR = model_selection.GridSearchCV(estimator=clf_svm_NR, param_grid=parametres)\n",
    "grid_clf_svm_FS = model_selection.GridSearchCV(estimator=clf_svm_FS, param_grid=parametres)\n",
    "grid_clf_svm_R  = model_selection.GridSearchCV(estimator=clf_svm_R, param_grid=parametres)\n",
    "\n",
    "grid_clf_svm_NR.fit(X_train_NR,y_train)\n",
    "grid_clf_svm_FS.fit(X_train_FS,y_train)\n",
    "grid_clf_svm_R.fit(X_train_R,y_train)\n",
    "\n",
    "\n",
    "print('Best parameters, non reduced dataset:',grid_clf_svm_NR.best_params_) \n",
    "print('Best parameters, dataset with feature reduction:',grid_clf_svm_FS.best_params_) \n",
    "print('Best parameters, reduced dataset:',grid_clf_svm_R.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094231f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clf_svm_NR = grid_clf_svm_NR.predict(X_test_NR)\n",
    "y_pred_clf_svm_FS = grid_clf_svm_FS.predict(X_test_FS)\n",
    "y_pred_clf_svm_R  = grid_clf_svm_R.predict(X_test_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports / Results for the 3 datasets are similars / No Draws predicted except for the dataset with feature selection\n",
    "print('Non reduced Dataset (NR):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_clf_svm_NR)))\n",
    "print('Dataset with selected features (FS):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_clf_svm_FS)))\n",
    "print('Reduced Dataset (R):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_clf_svm_R)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad741897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print('Non reduced Dataset (NR):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_clf_svm_NR), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23dcea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset with selected features (FS):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_clf_svm_FS), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0210c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reduced Dataset (R):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_clf_svm_R), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102be23",
   "metadata": {},
   "source": [
    "## 2.4 Decision Tree and Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "parametres = {'max_depth': [1, 2, 3, 5, 7]}\n",
    "\n",
    "dtc_NR = DecisionTreeClassifier()\n",
    "dtc_FS = DecisionTreeClassifier()\n",
    "dtc_R  = DecisionTreeClassifier()\n",
    "\n",
    "grid_dtc_NR = GridSearchCV(estimator=dtc_NR, param_grid=parametres)\n",
    "grid_dtc_FS = GridSearchCV(estimator=dtc_FS, param_grid=parametres)\n",
    "grid_dtc_R  = GridSearchCV(estimator=dtc_R, param_grid=parametres)\n",
    "\n",
    "\n",
    "grid_dtc_NR.fit(X_train_NR,y_train)\n",
    "grid_dtc_FS.fit(X_train_FS,y_train)\n",
    "grid_dtc_R.fit(X_train_R,y_train)\n",
    "\n",
    "print('Best parameters, non reduced dataset:',grid_dtc_NR.best_params_) \n",
    "print('Best parameters, dataset with feature reduction:',grid_dtc_FS.best_params_) \n",
    "print('Best parameters, reduced dataset:',grid_dtc_R.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ebb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtc_NR = grid_dtc_NR.predict(X_test_NR)\n",
    "y_pred_dtc_FS = grid_dtc_FS.predict(X_test_FS)\n",
    "y_pred_dtc_R  = grid_dtc_R.predict(X_test_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports / Results for the 3 datasets are similars, reduced dataset gives best results / No Draws predicted\n",
    "print('Non reduced Dataset (NR):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_dtc_NR)))\n",
    "print('Dataset with selected features (FS):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_dtc_FS)))\n",
    "print('Reduced Dataset (R):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_dtc_R)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_NR = AdaBoostClassifier(base_estimator=dtc_NR, n_estimators=400)\n",
    "ac_FS = AdaBoostClassifier(base_estimator=dtc_FS, n_estimators=400)\n",
    "ac_R  = AdaBoostClassifier(base_estimator=dtc_R,  n_estimators=400)\n",
    "\n",
    "ac_NR.fit(X_train_NR,y_train)\n",
    "ac_FS.fit(X_train_FS,y_train)\n",
    "ac_R.fit(X_train_R,y_train)\n",
    "\n",
    "y_pred_ac_NR = ac_NR.predict(X_test_NR)\n",
    "y_pred_ac_FS = ac_FS.predict(X_test_FS)\n",
    "y_pred_ac_R  = ac_R.predict(X_test_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316af32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports  / AdaBoost is one of the few models that gives draw prediction\n",
    "# Reduced dataset has lower scores\n",
    "print('Non reduced Dataset (NR):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_ac_NR)))\n",
    "print('Dataset with selected features (FS):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_ac_FS)))\n",
    "print('Reduced Dataset (R):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_ac_R)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66661362",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Non reduced Dataset (NR):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_ac_NR), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset with selected features (FS):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_ac_FS), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc499b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reduced Dataset (R):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_ac_R), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e0f2c",
   "metadata": {},
   "source": [
    "##  2.5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parametres = {'max_depth': [1, 2, 3, 5, 7, 10],'n_estimators': [10, 30, 50, 100] }\n",
    "\n",
    "forest_NR = RandomForestClassifier(random_state=0)\n",
    "forest_FS = RandomForestClassifier(random_state=0)\n",
    "forest_R = RandomForestClassifier(random_state=0)\n",
    "\n",
    "\n",
    "grid_forest_NR = GridSearchCV(estimator=forest_NR, param_grid=parametres)\n",
    "grid_forest_FS = GridSearchCV(estimator=forest_FS, param_grid=parametres)\n",
    "grid_forest_R = GridSearchCV(estimator=forest_R, param_grid=parametres)\n",
    "\n",
    "\n",
    "grid_forest_NR.fit(X_train_NR,y_train)\n",
    "grid_forest_FS.fit(X_train_FS,y_train)\n",
    "grid_forest_R.fit(X_train_R,y_train)\n",
    "\n",
    "print('Best parameters, non reduced dataset:',grid_forest_NR.best_params_) \n",
    "print('Best parameters, dataset with feature reduction:',grid_forest_FS.best_params_) \n",
    "print('Best parameters, reduced dataset:',grid_forest_R.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe941212",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_NR = grid_forest_NR.predict(X_test_NR)\n",
    "y_pred_rf_FS = grid_forest_FS.predict(X_test_FS)\n",
    "y_pred_rf_R  = grid_forest_R.predict(X_test_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd79ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports / The reduced dataset gives the best performences / No Draws predicted\n",
    "print('Non reduced Dataset (NR):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_rf_NR)))\n",
    "print('Dataset with selected features (FS):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_rf_FS)))\n",
    "print('Reduced Dataset (R):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_rf_R)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea559f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Non reduced Dataset (NR):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_rf_NR), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ec959",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset with selected features (FS):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_rf_FS), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1136ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reduced Dataset (R):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_rf_R), rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variable importance is plotted with its standard deviation for all trees considered\n",
    "forest_NR = RandomForestClassifier(random_state=0, max_depth =3, n_estimators = 30)\n",
    "forest_NR.fit(X_train_NR,y_train)\n",
    "\n",
    "importances = forest_NR.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest_NR.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=X_train.columns.values)\n",
    "forest_importances = forest_importances[forest_importances.argsort().values]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_xticklabels(forest_importances.index, rotation='vertical')\n",
    "ax.set_title(\"Feature importances\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f45d8c6",
   "metadata": {},
   "source": [
    "##  2.6 XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57698d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target is converted in numerical variable: H = 1, D = 0, A=-1\n",
    "y_train_xgb = y_train.replace({'H': 1, 'D': 0, 'A': -1})\n",
    "y_test_xgb  =  y_test.replace({'H': 1, 'D': 0, 'A': -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "train_xgb = xgb.DMatrix(data=X_train, label=y_train_xgb)\n",
    "\n",
    "train_xgb_NR = xgb.DMatrix(data=X_train_NR, label=y_train_xgb)\n",
    "test_xgb_NR  = xgb.DMatrix(data=X_test_NR, label=y_test_xgb)\n",
    "\n",
    "train_xgb_FS = xgb.DMatrix(data=X_train_FS, label=y_train_xgb)\n",
    "test_xgb_FS  = xgb.DMatrix(data=X_test_FS, label=y_test_xgb)\n",
    "\n",
    "train_xgb_R = xgb.DMatrix(data=X_train_R, label=y_train_xgb)\n",
    "test_xgb_R  = xgb.DMatrix(data=X_test_R, label=y_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d093654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_CV = {'max_depth': range(2, 3, 5), 'num_boost_round': [10, 30, 50, 100], 'learning_rate': [0.005, 0.01, 0.05]}\n",
    "\n",
    "\n",
    "xgb_ini_NR = xgb.XGBClassifier(objective='multi:softprob')\n",
    "xgb_ini_FS = xgb.XGBClassifier(objective='multi:softprob')\n",
    "xgb_ini_R = xgb.XGBClassifier(objective='multi:softprob')\n",
    "\n",
    "grid_xgb_NR = GridSearchCV(estimator=xgb_ini_NR, param_grid=param_CV, scoring = 'f1', cv = 4)\n",
    "grid_xgb_FS = GridSearchCV(estimator=xgb_ini_FS, param_grid=param_CV, scoring = 'f1', cv = 4)\n",
    "grid_xgb_R = GridSearchCV(estimator=xgb_ini_R, param_grid=param_CV, scoring = 'f1', cv = 4)\n",
    "\n",
    "grid_xgb_NR.fit(X_train_NR,y_train)\n",
    "grid_xgb_FS.fit(X_train_FS,y_train)\n",
    "grid_xgb_R.fit(X_train_R,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ce8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters, non reduced dataset:',grid_xgb_NR.best_params_) \n",
    "print('Best parameters, dataset with feature reduction:',grid_xgb_FS.best_params_) \n",
    "print('Best parameters, reduced dataset:',grid_xgb_R.best_params_) \n",
    "# No out of bounds values could be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20430ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_u_xgb_NR = grid_xgb_NR.predict(X_test_NR)\n",
    "y_pred_u_xgb_FS = grid_xgb_FS.predict(X_test_FS)\n",
    "y_pred_u_xgb_R  = grid_xgb_R.predict(X_test_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports / The reduced dataset gives better performences / No Draws predicted\n",
    "print('Non reduced Dataset (NR):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_u_xgb_NR)))\n",
    "print('Dataset with selected features (FS):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_u_xgb_FS)))\n",
    "print('Reduced Dataset (R):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_u_xgb_R)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Non reduced Dataset (NR):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_u_xgb_NR), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset with selected features (FS):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_u_xgb_FS), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed36123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reduced Dataset (R):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_u_xgb_R), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance is plotted via the parameter importance type: 'Gain' and 'weight' (mean reduction of the loss function between nodes).\n",
    "xgb.plot_importance(grid_xgb_NR.best_estimator_, max_num_features=15, importance_type = 'gain');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(grid_xgb_NR.best_estimator_, max_num_features=15, importance_type = 'weight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025288ac",
   "metadata": {},
   "source": [
    "##  2.7 Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26deb86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier with 'soft' vote considering that our models are well parametrized\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    " \n",
    "vclf_NR = VotingClassifier(estimators=[('cfl', grid_clf_NR), ('knn', grid_knn_NR), ('svm', grid_clf_svm_NR), \n",
    "                                       ('dtc_boost', ac_NR), ('Rforest', grid_forest_NR), ('XGB', grid_xgb_NR)], voting='soft')\n",
    "vclf_FS = VotingClassifier(estimators=[('cfl', grid_clf_FS), ('knn', grid_knn_FS), ('svm', grid_clf_svm_NR), \n",
    "                                       ('dtc_boost', ac_FS), ('Rforest', grid_forest_FS), ('XGB', grid_xgb_FS)], voting='soft')\n",
    "vclf_R  = VotingClassifier(estimators=[ ('cfl', grid_clf_R), ('knn', grid_knn_R) , ('svm', grid_clf_svm_NR), \n",
    "                                       ('dtc_boost',ac_R), ('Rforest', grid_forest_R), ('XGB', grid_xgb_R)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ddba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performances:\n",
    "vclf_NR.fit(X_train_NR, y_train)\n",
    "vclf_FS.fit(X_train_FS, y_train)\n",
    "vclf_R.fit(X_train_R, y_train)\n",
    "\n",
    "y_pred_vcfl_NR = vclf_NR.predict(X_test_NR)\n",
    "y_pred_vcfl_FS = vclf_FS.predict(X_test_FS)\n",
    "y_pred_vcfl_R  = vclf_R.predict(X_test_R)\n",
    "\n",
    "#pd.crosstab(y_test, y_pred_vcfl, rownames=['Classe réelle'], colnames=['Classe prédite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports / Results for the 3 datasets are similars / No Draws predicted\n",
    "print('Non reduced Dataset (NR):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_vcfl_NR)))\n",
    "print('Dataset with selected features (FS):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_vcfl_FS)))\n",
    "print('Reduced Dataset (R):')\n",
    "print(classification_report(y_test, pd.DataFrame(y_pred_vcfl_R)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea4b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Non reduced Dataset (NR):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_vcfl_NR), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e11a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset with selected features (FS):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_vcfl_FS), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68525400",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reduced Dataset (R):')\n",
    "pd.crosstab(y_test, pd.Series(y_pred_vcfl_R), rownames=['Real'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8286c555",
   "metadata": {},
   "source": [
    "# 3 Comparaisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5350ed42",
   "metadata": {},
   "source": [
    "Voting Classifier seems to gives the performeaces: 0.52 f1-score for 'A' and 0.66 for 'H'and 0.26 for 'D'\n",
    "This results can be compered with the best bookmaker predictions. \n",
    "From the odds, the prediction of each bookmaker is deduced (that is the lowest odd). Then using the match results, classification reports are computed in order to select the best bookmaker and compare its results with our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookmakers = pd.read_csv('df_stats_cotes.csv', index_col = 0)\n",
    "df_bookmakers = df_bookmakers.reset_index(drop=True).set_index('match_id')\n",
    "df_bookmakers = df_bookmakers.drop('index',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be60450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bookmakers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f6c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmaker_list = ['B365', 'LB', 'PS', 'WH', 'VC', 'PSC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdcfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bookmaker = df_bookmakers[df_bookmakers['season']=='2017_2018'][bookmaker_list[0]+'R'].reset_index(drop=True)\n",
    "y_test = df_bookmakers[df_bookmakers['season']=='2017_2018'][target_list].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos, bookies in enumerate(bookmaker_list):\n",
    "  y_pred_bookmaker = df_bookmakers[df_bookmakers['season']=='2017_2018'][bookies+'R'].reset_index(drop=True)\n",
    "  print(bookies)  \n",
    "  print(classification_report(y_test, pd.DataFrame(y_pred_bookmaker)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487e55e",
   "metadata": {},
   "source": [
    "B365 and WH have the best results, they both have a f1-score of 0.55 for 'A' and 0.68 for 'H'.\n",
    "Voting Classifier has a 0.52 f1-score for 'A' and 0.66 for 'H'and 0.26 for 'D'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4a377b",
   "metadata": {},
   "source": [
    "From the results is section 2 and 3, the following observations can be made:\n",
    "- Classification models used have difficulties to predict draws\n",
    "- Results are similar to Bookmakers predictions (where no draws are predicted) but are never superior\n",
    "- The voting classifier seems to be our best model when considering the f1-score\n",
    "- Results for reduced datasets (FS or R) are similar to non reduced model which makes the reduced dataset interesting to use\n",
    "- When it has been possible, the importance of variables where studied: the number of passes are often among the most important feature. The rating (differences between strikers and defense for instance) can also impact the classification result, in a less important way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a17043f",
   "metadata": {},
   "source": [
    "# 4 Betting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sure bets (and its drawbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelly criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba18387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain plot"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
